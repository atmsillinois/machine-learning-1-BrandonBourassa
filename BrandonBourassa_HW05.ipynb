{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 models used to see which does better in predicting rain rate.\n",
    "\n",
    "#### - Linear Regression Model: This model is used in Part 1 to perform multiple linear regression on the dataset.\n",
    "\n",
    "#### - Polynomial Regression Model: Polynomial regression is used in Part 2, where a grid search is conducted to find the best polynomial regression model in terms of R^2\n",
    "\n",
    "#### - Random Forest Regressor Model: Part 3 utilizes the Random Forest Regressor, and a grid search is performed to find the best combination of hyperparameters for this model, optimizing it based on the R^2 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Split the data into a 70-30 split for training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Zh (dBZ)', 'Zdr (dB)', 'Ldr (dB)', 'Kdp (deg km-1)',\n",
       "       'Ah (dBZ/km)', 'Adr (dB/km)', 'R (mm/hr)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('homework/radar_parameters.csv') \n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X = data[['Zh (dBZ)', 'Zdr (dB)', 'Ldr (dB)', 'Kdp (deg km-1)', 'Ah (dBZ/km)', 'Adr (dB/km)']] # Features\n",
    "y = data['R (mm/hr)'] # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (70-30 split)\n",
    "# Use train_test_split to split the data\n",
    "# Set test_size parameter to 0.3 that refers to the portion of the data to be in the test split.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Using the split created in (1), train a multiple linear regression dataset using the training dataset, and validate it using the testing dataset. Compare the R^2 and root mean square errors of model on the training and testing sets to a baseline prediction of rain rate using the formula Z = 200 * R^1.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline prediction using the provided equation Z = 200 * R^1.6\n",
    "baseline_pred_train = 200 * np.power(y_train, 1.6)\n",
    "baseline_pred_test = 200 * np.power(y_test, 1.6)\n",
    "\n",
    "# Baseline R^2\n",
    "baseline_r2_train = r2_score(y_train, baseline_pred_train)\n",
    "baseline_r2_test = r2_score(y_test, baseline_pred_test)\n",
    "\n",
    "# Baseline RMSE for the baseline prediction\n",
    "baseline_rmse_train = np.sqrt(mean_squared_error(y_train, baseline_pred_train))\n",
    "baseline_rmse_test = np.sqrt(mean_squared_error(y_test, baseline_pred_test))\n",
    "\n",
    "\n",
    "print(\"Baseline R^2 (Train):\", baseline_r2_train)\n",
    "print(\"Baseline R^2 (Test):\", baseline_r2_test)\n",
    "print(\"Baseline RMSE (Train):\", baseline_rmse_train)\n",
    "print(\"Baseline RMSE (Test):\", baseline_rmse_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE (Train): 22008.970472421162\n",
      "Baseline RMSE (Test): 24078.46941419433\n"
     ]
    }
   ],
   "source": [
    "# Baseline RMSE for the baseline prediction\n",
    "baseline_rmse_train = np.sqrt(mean_squared_error(y_train, baseline_pred_train))\n",
    "baseline_rmse_test = np.sqrt(mean_squared_error(y_test, baseline_pred_test))\n",
    "\n",
    "\n",
    "print(\"Baseline R^2 (Train):\", baseline_r2_train)\n",
    "print(\"Baseline R^2 (Test):\", baseline_r2_test)\n",
    "print(\"Baseline RMSE (Train):\", baseline_rmse_train)\n",
    "print(\"Baseline RMSE (Test):\", baseline_rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline R^2 (Train): -6875917.308315697\n",
      "Baseline R^2 (Test): -7216632.894739466\n",
      "Linear Regression R^2 (Train): 0.9879085512445995\n",
      "Linear Regression R^2 (Test): 0.9890992951689396\n",
      "Linear Regression RMSE (Train): 0.922940159028789\n",
      "Linear Regression RMSE (Test): 0.9358124742086971\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "lin_reg_pred_train = lin_reg.predict(X_train)\n",
    "lin_reg_pred_test = lin_reg.predict(X_test)\n",
    "lin_reg_rmse_train = np.sqrt(mean_squared_error(y_train, lin_reg_pred_train))\n",
    "lin_reg_rmse_test = np.sqrt(mean_squared_error(y_test, lin_reg_pred_test))\n",
    "lin_reg_r2_train = r2_score(y_train, lin_reg_pred_train)\n",
    "lin_reg_r2_test = r2_score(y_test, lin_reg_pred_test)\n",
    "\n",
    "print(\"Baseline R^2 (Train):\", baseline_r2_train)\n",
    "print(\"Baseline R^2 (Test):\", baseline_r2_test)\n",
    "print(\"Linear Regression R^2 (Train):\", lin_reg_r2_train)\n",
    "print(\"Linear Regression R^2 (Test):\", lin_reg_r2_test)\n",
    "print(\"Linear Regression RMSE (Train):\", lin_reg_rmse_train)\n",
    "print(\"Linear Regression RMSE (Test):\", lin_reg_rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The negative values for the baseline R^2 scores indicate that the baseline model performs significantly worse than a horizontal line (a model that always predicts the mean of the target variable). \n",
    "\n",
    "##### This suggests that the baseline model is a poor fit for the data. However, the R^2 scores for the linear regression model on both the training and testing sets are close to 1, indicating that the model explains a high percentage of the variance in the target variable. \n",
    "\n",
    "##### Additionally, the RMSE values for the linear regression model are relatively low, indicating that the model's predictions are close to the actual values. \n",
    "\n",
    "##### Overall, these results suggest that the linear regression model for rain prediction performs well on both the training and testing datasets and outperforms the baseline model significantly. This indicates that the linear regression model captures the underlying patterns in the data effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Repeat 1 doing a grid search over polynomial orders, using a grid search over orders 0-21, and use cross-validation of 7 folds. For the best polynomial model in terms of R^2, does it outperform the baseline and the linear regression model in terms of R^2 and root mean square error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression with Grid Search\n",
    "poly_reg = make_pipeline(PolynomialFeatures(), LinearRegression())\n",
    "\n",
    "param_grid_poly = {'polynomialfeatures__degree': np.arange(0, 22)}\n",
    "\n",
    "grid_search_poly = GridSearchCV(poly_reg, param_grid_poly, cv=7, scoring='r2')\n",
    "grid_search_poly.fit(X_train, y_train)\n",
    "\n",
    "best_poly_model = grid_search_poly.best_estimator_\n",
    "best_poly_pred_train = best_poly_model.predict(X_train)\n",
    "best_poly_pred_test = best_poly_model.predict(X_test)\n",
    "best_poly_rmse_train = np.sqrt(mean_squared_error(y_train, best_poly_pred_train))\n",
    "best_poly_rmse_test = np.sqrt(mean_squared_error(y_test, best_poly_pred_test))\n",
    "best_poly_r2_train = r2_score(y_train, best_poly_pred_train)\n",
    "best_poly_r2_test = r2_score(y_test, best_poly_pred_test)\n",
    "\n",
    "print(\"Best Polynomial Regression R^2 (Train):\", best_poly_r2_train)\n",
    "print(\"Best Polynomial Regression R^2 (Test):\", best_poly_r2_test)\n",
    "print(\"Best Polynomial Regression RMSE (Train):\", best_poly_rmse_train)\n",
    "print(\"Best Polynomial Regression RMSE (Test):\", best_poly_rmse_test)\n",
    "\n",
    "# Comparison with Baseline and Linear Regression\n",
    "print(\"\\nComparison with Baseline and Linear Regression:\")\n",
    "print(\"Baseline R^2 (Test):\", baseline_r2_test)\n",
    "print(\"Linear Regression R^2 (Test):\", lin_reg_r2_test)\n",
    "print(\"Random Forest R^2 (Test):\", rf_r2_test)\n",
    "print(\"Best Polynomial Regression R^2 (Test):\", best_poly_r2_test)\n",
    "print(\"Best Polynomial Regression RMSE (Test):\", best_poly_rmse_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Repeat 1 with a Random Forest Regressor, and perform a grid search on the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor with Grid Search\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='r2')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "best_rf_pred_train = best_rf_model.predict(X_train)\n",
    "best_rf_pred_test = best_rf_model.predict(X_test)\n",
    "best_rf_rmse_train = np.sqrt(mean_squared_error(y_train, best_rf_pred_train))\n",
    "best_rf_rmse_test = np.sqrt(mean_squared_error(y_test, best_rf_pred_test))\n",
    "best_rf_r2_train = r2_score(y_train, best_rf_pred_train)\n",
    "best_rf_r2_test = r2_score(y_test, best_rf_pred_test)\n",
    "\n",
    "print(\"Best Random Forest Regression R^2 (Train):\", best_rf_r2_train)\n",
    "print(\"Best Random Forest Regression R^2 (Test):\", best_rf_r2_test)\n",
    "print(\"Best Random Forest Regression RMSE (Train):\", best_rf_rmse_train)\n",
    "print(\"Best Random Forest Regression RMSE (Test):\", best_rf_rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the results of all three models to the baseline\n",
    "\n",
    "# Baseline metrics\n",
    "print(\"Baseline R^2 (Test):\", baseline_r2_test)\n",
    "print(\"Baseline RMSE (Test):\", baseline_rmse_test)\n",
    "print()\n",
    "\n",
    "# Linear Regression metrics\n",
    "print(\"Linear Regression R^2 (Test):\", lin_reg_r2_test)\n",
    "print(\"Linear Regression RMSE (Test):\", lin_reg_rmse_test)\n",
    "print()\n",
    "\n",
    "# Polynomial Regression metrics\n",
    "print(\"Best Polynomial Regression R^2 (Test):\", best_poly_r2_test)\n",
    "print(\"Best Polynomial Regression RMSE (Test):\", best_poly_rmse_test)\n",
    "print()\n",
    "\n",
    "# Random Forest Regression metrics\n",
    "print(\"Best Random Forest Regression R^2 (Test):\", best_rf_r2_test)\n",
    "print(\"Best Random Forest Regression RMSE (Test):\", best_rf_rmse_test)\n",
    "print()\n",
    "\n",
    "# Comparing to Baseline\n",
    "print(\"Linear Regression Improvement in R^2 over Baseline:\", lin_reg_r2_test - baseline_r2_test)\n",
    "print(\"Linear Regression Improvement in RMSE over Baseline:\", baseline_rmse_test - lin_reg_rmse_test)\n",
    "print()\n",
    "\n",
    "print(\"Polynomial Regression Improvement in R^2 over Baseline:\", best_poly_r2_test - baseline_r2_test)\n",
    "print(\"Polynomial Regression Improvement in RMSE over Baseline:\", baseline_rmse_test - best_poly_rmse_test)\n",
    "print()\n",
    "\n",
    "print(\"Random Forest Regression Improvement in R^2 over Baseline:\", best_rf_r2_test - baseline_r2_test)\n",
    "print(\"Random Forest Regression Improvement in RMSE over Baseline:\", baseline_rmse_test - best_rf_rmse_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
